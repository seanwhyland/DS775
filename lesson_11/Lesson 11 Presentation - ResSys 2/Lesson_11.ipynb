{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# execute to import notebook styling for tables and width etc.\n",
    "from IPython.core.display import HTML\n",
    "import urllib.request\n",
    "response = urllib.request.urlopen('https://raw.githubusercontent.com/DataScienceUWL/DS775v2/master/ds755.css')\n",
    "HTML(response.read().decode(\"utf-8\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=18>Lesson 11: Recommender Systems 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the examples and use the code files provided from from chapters 5-7 in **Hands-On Recommendation Systems with Python** by Rounak Banik to do the following self-assessment exercises.  \n",
    "\n",
    "The self-assessments in this lesson will be using a subset of data from the Book-Crossing dataset.  Click <a href = http://www2.informatik.uni-freiburg.de/~cziegler/BX/> here </a> for more details on the Book-Crossing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Collaborative Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: Setting up the File </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file **BX-Book-Ratings-3000.csv** (found in the presentation download for this lesson) is loaded here for you, though you may need to change the file path unless you create the same folder structure.    \n",
    "\n",
    "The rating scale for book ratings goes from 0 to 10.  Rating scales that include 0 have computational difficulties, so the rating scale will be shifted up by 1, so it runs from 1 to 11. This is also done for you in the cell below.\n",
    "\n",
    "The code for this is give for you to use. Run it to load and reduce the file and then do the following:\n",
    "\n",
    "* display the first 5 lines of the data (get familiar with the data frame)\n",
    "* calculate the mean book rating for all books (just to get an idea)\n",
    "* split the data set so that 70\\% of a users ratings are in the training set and 30\\% are in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "import pandas as pd\n",
    "bx = pd.read_csv('./data/BX-Book-Ratings-3000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: Baseline RMSE to Assess Model Performance </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a baseline model that assigns a neutral rating and compute the RMSE of these simple \"predictions\" using the testing set.\n",
    "\n",
    "A neutral rating would occur at the midpoint of the rating scale.  Since the rating scale now goes from 1 to 11, a neutral rating will be (11+1)/2 = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: Weighted Mean User-Based Filter </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a ratings matrix from the data frame of users, books, and ratings and build a user-based collaborative filtering model that weights mean rank using cosine similarity among users.  Fit the model on the training set and compute the RMSE for this model using the test set and compare it to the RMSE of the baseline model.  Is it better than baseline?  (*i.e.* is the RMSE smaller?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: Weighted Mean Item-Based Filter </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new ratings matrix from the data frame of users, books, and ratings with the rows defined by books (*i.e.* items) and columns defined by users to build an item-based collaborative filtering model that weights mean rank using cosine similarity among items.  Fit the model on the training set and compute the RMSE for this model on the test and compare it to the RMSEs of the baseline and weighted mean user-based models.  Is this one better than baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: kNN-Based Collaborative Filter  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the *surprise* library in Python to build an kNN-based collaborative filtering model for the BX-Books ratings.  Fit the model on the full data set and compute the average RMSE for this model from 5 cross-validations. Compare it to the RMSEs of the baseline, weighted mean user-based, and weighted mean item-based models previously obtained.\n",
    "\n",
    "*Note:* evaluate *is no longer available in the* surprise *package, so do not include it in the list of methods to import. Replace the line (from Banik's code on the kNN model):*\n",
    "\n",
    "**evaluate(knn, data, measures=['RMSE'])**\n",
    "\n",
    "*with the following lines of code:*\n",
    "\n",
    "**from surprise.model_selection import cross_validate**\n",
    "\n",
    "**cross_validate(knn, data, measures=['RMSE'], cv=5, verbose=True)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: SVD Filter  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the *surprise* library in Python to build a filtering model based on singular-value decomposition (SVD).  Fit the model on the full data set and compute the average RMSE for this model from 5 cross-validations and compare it to the RMSEs of the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: Hybrid Recommender </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a recommender system that is a hybrid of an item-based collaborative filter and the SVD collaborative filter.  \n",
    "Your recommender should do the following:\n",
    "\n",
    "* Take in a user ID and book title as user input\n",
    "* Use cosine similarity among books to find the 25 most similar books\n",
    "* Compute the predicted ratings that the user might give to these 25 books using the SVD collaborative filter\n",
    "\n",
    "Return the top 10 book recommendations along with their predicted ratings when user **31315** enters the book with ISBN **440214041**.  \n",
    "\n",
    "Use the entire data set to build this model (*i.e.* don't split into training and testing sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One More Self-Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Self-Assessment: Type of Recommenders </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the type of recommender system with its brief description by matching the letter of the recommender system with the number of the description.\n",
    "\n",
    "**Recommenders**\n",
    "\n",
    "a. simple \n",
    "\n",
    "b. knowledge-based\n",
    "\n",
    "c. content-based\n",
    "\n",
    "d. user-based collaborative filters \n",
    "\n",
    "e. item-based collaborative filters  \n",
    "\n",
    "f. hybrid \n",
    "\n",
    "\n",
    "**Descriptions**\n",
    "\n",
    "1.  This model provides recommendations based on items with similar descriptions and features that match the profile of the user.\n",
    "\n",
    "\n",
    "2. Uses similarity among items to to create an ordered list of recommended items based on metric of interest (*i.e.* ratings).\n",
    "\n",
    "\n",
    "3. Recommendations made to users are based on an ordered list of items that are ranked according to some metric of interest (*i.e.* ratings).\n",
    "\n",
    "\n",
    "4. A combination of recommender systems that makes use of the advantages of each system used.\n",
    "\n",
    "\n",
    "5. Items are recommended that meet the specifics and preferences elicited from users and are ranked according to  metric of interest (*i.e.* ratings).\n",
    "\n",
    "\n",
    "6.  Uses similarity among users to create an ordered list of recommended items based on metric of interest (*i.e.* ratings).\n",
    "\n",
    "\n",
    "**Put the letter of the recommender system with the number of its description.**\n",
    "\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    " \n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234.363px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
